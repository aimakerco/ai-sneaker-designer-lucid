{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AI Maker - Sneaker Designer - Feature Inversion with Lucid",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aimakerco/ai-sneaker-designer-lucid/blob/master/AI_Maker_Sneaker_Designer_Feature_Inversion_with_Lucid.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FOkosm79uqzN",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cH2NMAkCuu5X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GS4kqcEJuy5R",
        "colab_type": "text"
      },
      "source": [
        "#AI Maker - Sneaker Designer - Feature Inversion with Lucid\n",
        "\n",
        "![Original Converse Tennis Shoes - Source Wikipedia](https://aimaker.co/wp-content/uploads/AI-Maker-Converse-Original-220.png)\n",
        "\n",
        "Original Tennis Shoe - Source Wikipedia\n",
        "\n",
        "![AI-Maker-Converse Tennis Shoe Inspiration](https://aimaker.co/wp-content/uploads/AI-Maker-Converse-Sneakers-AI-220.png)\n",
        "\n",
        "AI Maker - Converse Sneaker Inspiration\n",
        "\n",
        "# Overview of AI Sneaker Maker\n",
        "\n",
        "**This Notebook is based on the excellent notebook - [Lucid Notebook](https://colab.research.google.com/github/tensorflow/lucid/blob/master/notebooks/misc/feature_inversion_caricatures.ipynb)**\n",
        "\n",
        "I made changes to it to make it easier to design things with.  You can upload fashion design images and run them through this notebook to come up with new design inspirations.\n",
        "\n",
        "For more details on this Notebook check out our post - [AI Maker - How to Become a Fashion Designer In Under 15 Minutes using Artificial Intelligence](https://aimaker.co/how-to-become-fashion-designer-under-15-minutes-using-artificial-intelligence)\n",
        "\n",
        "# Download Your Ideas\n",
        "The images generated from this notebook are saved to the local system.  You can download them by selecting the Files tab.  The images are stored in the /content/AI-Maker-lucid-fashion/ directory.  \n",
        " \n",
        "1.   Select the image then right click on it.\n",
        "2.   Select Download to download the image to your local system.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Original Notebook Directions\n",
        "      \"This notebook uses  [**Lucid**](https://github.com/tensorflow/lucid) to produce feature inversion caricatures that are similar in spirit to the activation grids in [The Building Blocks of Interpretability](https://distill.pub/2018/building-blocks/). \n",
        "\n",
        "      This is slightly similar to the technique described by [Mahendran and Vedaldi](https://arxiv.org/pdf/1412.0035.pdf). However, we use a dot product objective, instead of L2 difference, and use transformation robustness to reduce artifacts. \n",
        "\n",
        "      This notebook doesn't introduce the abstractions behind lucid; you may wish to also read the [Lucid tutorial](https://colab.research.google.com/github/tensorflow/lucid/blob/master/notebooks/tutorial.ipynb).\n",
        "\n",
        "      **Note**: The easiest way to use this tutorial is as a colab notebook, which allows you to dive in with no setup. We recommend you enable a free GPU by going:\n",
        "\n",
        "      > **Runtime**   →   **Change runtime type**   →   **Hardware Accelerator: GPU**\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RDCKv_xfviPQ",
        "colab_type": "text"
      },
      "source": [
        "## Install, Import, Load Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oS7yUMsVpKVI",
        "colab_type": "code",
        "outputId": "c5191148-a669-41a1-f621-29cbe0e2c967",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Install Lucid\n",
        "!pip install --quiet lucid==0.2.3\n",
        "\n",
        "# Import libraries\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import scipy.ndimage as nd\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "import lucid.modelzoo.vision_models as models\n",
        "import lucid.optvis.objectives as objectives\n",
        "import lucid.optvis.param as param\n",
        "import lucid.optvis.render as render\n",
        "import lucid.optvis.transform as transform\n",
        "from lucid.misc.io import show, load, save\n",
        "from lucid.misc.io.reading import read\n",
        "import time"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K     |████████                        | 10kB 21.2MB/s eta 0:00:01\r\u001b[K     |████████████████                | 20kB 3.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 30kB 4.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 40kB 5.0MB/s \n",
            "\u001b[?25h  Building wheel for lucid (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i0WCIQdQpR0O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import the InceptionV1 (GoogLeNet) model from the Lucid modelzoo\n",
        "\n",
        "model = models.InceptionV1()\n",
        "model.load_graphdef()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2nWo_L_5v6ke",
        "colab_type": "text"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8EptVuiPruUj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def imgToModelSize(arr):\n",
        "  # this line produces 224 size image (small)\n",
        "  #W = model.image_shape[0]\n",
        "  # Increased from 224 to 512 for larger image files\n",
        "  W = 512\n",
        "  w, h, _ = arr.shape\n",
        "  s = float(W) / min(w,h)\n",
        "  arr = nd.zoom(arr, [s, s, 1], mode=\"nearest\")\n",
        "  w, h, _ = arr.shape\n",
        "  dw, dh = (w-W)//2, (h-W)//3\n",
        "  return arr[dw:dw+W, dh:dh+W]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_CrXNcM-pbpw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@objectives.wrap_objective\n",
        "def dot_compare(layer, batch=1, cossim_pow=0):\n",
        "  def inner(T):\n",
        "    dot = tf.reduce_sum(T(layer)[batch] * T(layer)[0])\n",
        "    mag = tf.sqrt(tf.reduce_sum(T(layer)[0]**2))\n",
        "    cossim = dot/(1e-6 + mag)\n",
        "    return dot * cossim ** cossim_pow\n",
        "  return inner"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DcuVtAQ-poGv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def feature_inversion(img=None, layer=None, n_steps=512, cossim_pow=0.0):\n",
        "  file_name = ''\n",
        "  x = 0\n",
        "  with tf.Graph().as_default(), tf.Session() as sess:\n",
        "    img = imgToModelSize(img)\n",
        "    x = x + 1\n",
        "    \n",
        "    objective = objectives.Objective.sum([\n",
        "        1.0 * dot_compare(layer, cossim_pow=cossim_pow),\n",
        "        objectives.blur_input_each_step(),\n",
        "    ])\n",
        "\n",
        "    t_input = tf.placeholder(tf.float32, img.shape)\n",
        "    param_f = param.image(img.shape[0], decorrelate=True, fft=True, alpha=False)\n",
        "    param_f = tf.stack([param_f[0], t_input])\n",
        "\n",
        "    transforms = [\n",
        "      transform.pad(8, mode='constant', constant_value=.5),\n",
        "      transform.jitter(8),\n",
        "      transform.random_scale([0.9, 0.95, 1.05, 1.1] + [1]*4),\n",
        "      transform.random_rotate(range(-5, 5) + [0]*5),\n",
        "      transform.jitter(2),\n",
        "    ]\n",
        "\n",
        "    T = render.make_vis_T(model, objective, param_f, transforms=transforms)\n",
        "    loss, vis_op, t_image = T(\"loss\"), T(\"vis_op\"), T(\"input\")\n",
        "\n",
        "    tf.global_variables_initializer().run()\n",
        "    for i in range(n_steps): _ = sess.run([vis_op], {t_input: img})\n",
        "\n",
        "    result = t_image.eval(feed_dict={t_input: img})\n",
        "    # set the file name with the path\n",
        "    timestr = time.strftime(\"%Y%m%d-%H%M%S\")\n",
        "    \n",
        "    file_name = '/content/AI-Maker-lucid-sneaker/lucid_sneaker_method_' + layer + '_image_' + '_cos_' + str(cossim_pow) + '_' + timestr + '.jpg'\n",
        "    # save the graphic as a JPEG file\n",
        "    save(result[0], file_name, quality=90)\n",
        "    show(result[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G9KnR3olwPzd",
        "colab_type": "text"
      },
      "source": [
        "# Designing with Neural Networks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n2Yh2102sZXr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# set the directory for the output images (inspirations)\n",
        "!mkdir /content/AI-Maker-lucid-sneaker\n",
        "\n",
        "layers = ['conv2d%d' % i for i in range(0, 3)] + ['mixed3a', 'mixed3b', \n",
        "                                                  'mixed4a', 'mixed4b', 'mixed4c', 'mixed4d', 'mixed4e',\n",
        "                                                  'mixed5a', 'mixed5b']\n",
        "\n",
        "#img = ''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s-uQ13WjwmJ-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get the URLs for \n",
        "urls = [\"https://upload.wikimedia.org/wikipedia/commons/thumb/0/0c/Burnetie_and_socks.jpg/512px-Burnetie_and_socks.jpg\",\n",
        "        \"https://upload.wikimedia.org/wikipedia/commons/0/0d/Bape_Roadsta_%282009-03-21_00.20.04_by_Christian_H.%29.jpg\"]\n",
        "\n",
        "for url in urls:\n",
        "    try:\n",
        "        print('Loading URL - ' + url)\n",
        "        img = load(url)\n",
        "        show(imgToModelSize(img))\n",
        "        for layer in layers:\n",
        "          print('Layer - ' + layer)\n",
        "          feature_inversion(img, layer=layer)\n",
        "          print \"\"\n",
        "    except ValueError:\n",
        "        print('********   Error Occurred on URL - ' + url + ' *************')\n",
        "        pass\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X9fhtT857j0w",
        "colab_type": "text"
      },
      "source": [
        "## Varying Cossine  on the Designs\n",
        "\n",
        "The Cossine value forces the design to be closer to the orginal image.  This can help with new inspirations for design ideas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r8xH-fLD7uSK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('Original Image')\n",
        "show(imgToModelSize(img))\n",
        "for cossim in [0.0, 0.5, 1.0, 2.0]:\n",
        "  print cossim\n",
        "  feature_inversion(img, layer='mixed4d', cossim_pow=cossim)\n",
        "  print \"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V0Kd7Tcpw4Pn",
        "colab_type": "text"
      },
      "source": [
        "# Upload your own Files for new Design Ideas\n",
        "\n",
        "Process the Images through the Layers & Cossines to get the most Inspiration for new ideas.  You will need to limit the uploaded images to 640x640.  Larger images can cause the system to produce errors.  If you get an error try loading a lower resolution image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "guFEpl3y2wYf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Upload your Own File(s)\n",
        "uploaded = files.upload()\n",
        "for fn in uploaded.keys():\n",
        "  img = load(fn)\n",
        "  show(imgToModelSize(img))\n",
        "  for layer in layers:\n",
        "    print layer\n",
        "    feature_inversion(img, layer=layer)\n",
        "    print \"\"\n",
        "    for cossim in [0.0, 0.5, 1.0, 2.0]:\n",
        "      print('Layer - ' + layer + ', Cossim - ' + str(cossim))\n",
        "      feature_inversion(img, layer=layer, cossim_pow=cossim)\n",
        "      print \"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Lfmr8OaFk74",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Extra Credit - here are some more dresses to design\n",
        "\n",
        "urls = [\"https://upload.wikimedia.org/wikipedia/commons/thumb/a/a5/Black_Converse_sneakers.JPG/512px-Black_Converse_sneakers.JPG\",\n",
        "        \"https://upload.wikimedia.org/wikipedia/commons/4/49/OBJSark-1_White_and_Black.png\",\n",
        "        \"https://upload.wikimedia.org/wikipedia/commons/3/36/AdidasSuperstarII.jpg\"]\n",
        "\n",
        "\n",
        "for url in urls:\n",
        "    try:\n",
        "        print('Loading URL - ' + url)\n",
        "        img = load(url)\n",
        "        show(imgToModelSize(img))\n",
        "        for layer in layers:\n",
        "          print layer\n",
        "          feature_inversion(img, layer=layer)\n",
        "          print \"\"\n",
        "          for cossim in [0.0, 0.5, 1.0, 2.0]:\n",
        "            print('Layer - ' + layer + ', Cossim - ' + str(cossim))\n",
        "            feature_inversion(img, layer=layer, cossim_pow=cossim)\n",
        "            print \"\"\n",
        "    except ValueError:\n",
        "        print('********   Error Occurred on URL - ' + url + ' *************')\n",
        "        pass\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YO3xpAXY8ZLd",
        "colab_type": "text"
      },
      "source": [
        "# More Sneaker Images\n",
        "Here are some additional sneaker images to play with. Add these to the **urls** list above to process them.  Make sure and enclose them in brackets [ ] and seperate each item with a comma.\n",
        "\n",
        "\"https://upload.wikimedia.org/wikipedia/commons/4/46/Lyfn011.png\"\n",
        "\n",
        "\"https://upload.wikimedia.org/wikipedia/commons/thumb/c/c1/Karhu_shoe.jpg/512px-Karhu_shoe.jpg\"\n",
        "\n",
        "\"https://upload.wikimedia.org/wikipedia/commons/thumb/1/14/Vans_womans_shoe.JPG/512px-Vans_womans_shoe.JPG\"\n",
        "\n",
        "# Example\n",
        "\n",
        "urls = [\"https://upload.wikimedia.org/wikipedia/commons/4/46/Lyfn011.png\", \"https://upload.wikimedia.org/wikipedia/commons/thumb/c/c1/Karhu_shoe.jpg/512px-Karhu_shoe.jpg\"]\n"
      ]
    }
  ]
}